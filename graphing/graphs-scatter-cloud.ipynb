{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88cd4361",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T10:47:48.897048Z",
     "start_time": "2023-10-09T10:47:48.886676Z"
    }
   },
   "source": [
    "# Graphs\n",
    "\n",
    "Base version of the notebook that we used to generate the quality of service graphs. Comments are provided to aid in the usage of the notebook. Modifications may be necessary to get the code functioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e031e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T11:08:39.328140Z",
     "start_time": "2023-10-09T11:08:39.320241Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243a9b1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T11:08:39.616363Z",
     "start_time": "2023-10-09T11:08:39.331834Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Styling parameters for the generated graphs\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "params = {\n",
    "    'ytick.color': \"black\",\n",
    "    'xtick.color': \"black\",\n",
    "    'axes.labelcolor': \"black\",\n",
    "    'axes.edgecolor': \"black\",\n",
    "    'axes.linewidth': 1,\n",
    "    'text.usetex': True,\n",
    "    'font.family': \"serif\",\n",
    "    'font.weight': \"bold\",\n",
    "    'font.serif': [\"Computer Modern Serif\"],\n",
    "    'font.size': 24,\n",
    "}\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "plt.rcParams['font.size'] = 24\n",
    "plt.rcParams['axes.labelsize'] = 24\n",
    "plt.rcParams['xtick.labelsize'] = 24\n",
    "plt.rcParams['ytick.labelsize'] = 24\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef4935c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T11:08:40.390221Z",
     "start_time": "2023-10-09T11:08:39.621316Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read CSV files and combine into a single dataframe\n",
    "\n",
    "path = r'analysed_results' # ! CHANGE TO CORRECT PATH \n",
    "csv_files = glob.glob(os.path.join(path , \"*.csv\"))\n",
    "\n",
    "temp_list = []\n",
    "for filename in csv_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    temp_list.append(df)\n",
    "\n",
    "combined_data = pd.concat(temp_list, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30705f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T11:08:40.417765Z",
     "start_time": "2023-10-09T11:08:40.393441Z"
    },
    "code_folding": [
     5,
     6,
     80,
     136
    ]
   },
   "outputs": [],
   "source": [
    "# Dictionary/JSON structure containing the graphs to be created. \n",
    "# Top level graph structures are for each plot, and within that struct, the\n",
    "# individual graphs are subplots. \"Nice\" looking graphs requires adjusting of \n",
    "# the individual subplot parameters. \n",
    "\n",
    "graphs = {   \n",
    "    \"graph3\": {\n",
    "        \"name\": \"hybrid\",\n",
    "        \"data\": [\"scatter-cloud\"],\n",
    "        \"permutation_order\": [0],\n",
    "        \"plots\": {\n",
    "            \"plot1\": {\n",
    "                \"legends\": {\n",
    "                    \"exp\": [0, 1.2, 1, 0.2],\n",
    "                    'services': [0, 1.2, 1, 0.2],\n",
    "                },\n",
    "                \"legend_cols\": 2,\n",
    "                'legend_size': 20,\n",
    "                \"figsize\": [15, 10],\n",
    "                \"height_ratios\": [1, 1, 1, 1],\n",
    "                \"subplots\": (3, 2),\n",
    "                \"graphs\": {\n",
    "                    \"graph0\": {\n",
    "                        \"name\": \"FPS\",\n",
    "                        \"results_key\": \"fps\",\n",
    "                        \"graph_index\": 0,\n",
    "                        \"subplot_loc\": (0,0),\n",
    "                        \"filler\": False,\n",
    "                        \"y_axis_lims\": [0, 32],\n",
    "                        \"y_tick_marks\": [0, 31, 10],\n",
    "                    },\n",
    "                    \"graph1\": {\n",
    "                        \"name\": r\"\\begin{center}E2E Lat. (ms)\\end{center}\",\n",
    "                        \"results_key\": \"e2e\",\n",
    "                        \"graph_index\": 1,\n",
    "                        \"subplot_loc\": (1,0),\n",
    "                        \"filler\": False,\n",
    "                        \"y_axis_lims\": [0, 60],\n",
    "                        \"y_tick_marks\": [0, 61, 15],\n",
    "                    },\n",
    "                    \"graph2\": {\n",
    "                        \"name\": r\"\\begin{center}Service Lat. (ms)\\end{center}\",\n",
    "                        \"results_key\": \"services\",\n",
    "                        \"graph_index\": 2,\n",
    "                        \"subplot_loc\": (2, 0),\n",
    "                        \"filler\": False,\n",
    "                        \"y_axis_lims\": [0, 55],\n",
    "                        \"y_tick_marks\": [0, 51, 15],\n",
    "                    },\n",
    "                    \"graph3\": {\n",
    "                        \"name\": r\"\\begin{center}Mem. (GB)\\end{center}\",\n",
    "                        \"results_key\": \"memory\",\n",
    "                        \"graph_index\": 3,\n",
    "                        \"subplot_loc\": (0, 1),\n",
    "                        \"filler\": False,\n",
    "                        \"y_axis_lims\": [0, 10],\n",
    "                        \"y_tick_marks\": [0, 10, 2],\n",
    "                    },\n",
    "                    \"graph4\": {\n",
    "                        \"name\": r\"\\begin{center}CPU Util. (\\%)\\end{center}\",\n",
    "                        \"results_key\": \"cpu\",\n",
    "                        \"graph_index\": 4,\n",
    "                        \"subplot_loc\": (1, 1),\n",
    "                        \"filler\": False,\n",
    "                        \"y_axis_lims\": [0, 10],\n",
    "                        \"y_tick_marks\": [0, 9, 2],\n",
    "                    },\n",
    "                    \"graph5\": {\n",
    "                        \"name\": r\"\\begin{center}GPU Util. (\\%)\\end{center}\",\n",
    "                        \"results_key\": \"gpu_util\",\n",
    "                        \"graph_index\": 5,\n",
    "                        \"subplot_loc\": (2, 1),\n",
    "                        \"filler\": False,\n",
    "                        \"y_axis_lims\": [0, 35],\n",
    "                        \"y_tick_marks\": [0, 31, 10],\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2684b296",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T11:08:40.872859Z",
     "start_time": "2023-10-09T11:08:40.423322Z"
    },
    "code_folding": [
     0,
     2
    ]
   },
   "outputs": [],
   "source": [
    "# Variables for graph plotting \n",
    "\n",
    "colours = [\n",
    "    '3a77b2', 'f3812d', '459e32', 'ca2e33', '9169bb', '86574d', 'da7ac2',\n",
    "    'babc34', '4ebdcd'\n",
    "]\n",
    "\n",
    "service_dict = {\n",
    "    'primary': {\n",
    "        'colour': '#ef476f',\n",
    "        'loc': 0\n",
    "    },\n",
    "    'sift': {\n",
    "        'colour': '#ffd166',\n",
    "        'loc': 1\n",
    "    },\n",
    "    'encoding': {\n",
    "        'colour': '#06d6a0',\n",
    "        'loc': 2\n",
    "    },\n",
    "    'lsh': {\n",
    "        'colour': '#7bbee9',\n",
    "        'loc': 3\n",
    "    },\n",
    "    'matching': {\n",
    "        'colour': '#576aa8',\n",
    "        'loc': 4\n",
    "    },\n",
    "}\n",
    "\n",
    "bar_width = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9561dd99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T11:08:41.127819Z",
     "start_time": "2023-10-09T11:08:40.876924Z"
    },
    "code_folding": [
     0,
     3
    ]
   },
   "outputs": [],
   "source": [
    "# Dictionary containing the details of the servers, and the CPU/GPU cores \n",
    "# used for normalising the data\n",
    "\n",
    "server_dict = {\n",
    "    'gpu02': {\n",
    "        'label': 'Edge2 (E2)',\n",
    "        'shorthand': '(E2)'\n",
    "    }, \n",
    "    'cm-01-05-061': {\n",
    "        'label': 'Edge1 (E1)',\n",
    "    },\n",
    "    'ip-172-31-28-206': {\n",
    "        'label': 'Cloud (C)'\n",
    "    },\n",
    "    'E1': {\n",
    "        'hatch': 'xxx',\n",
    "        'cores': 10,\n",
    "        'cuda_cores': 4352\n",
    "    },\n",
    "    'E2': {\n",
    "        'hatch': '..',\n",
    "        'cores': 32,\n",
    "        'cuda_cores': 10752\n",
    "    },\n",
    "    'C': {\n",
    "        'hatch': '..',\n",
    "        'cores': 18,\n",
    "        'cuda_cores': 5120\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92508508",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T11:08:41.580311Z",
     "start_time": "2023-10-09T11:08:41.132907Z"
    },
    "code_folding": [
     2,
     26,
     75,
     97,
     108,
     145,
     178,
     211,
     243
    ]
   },
   "outputs": [],
   "source": [
    "# Functions to help in graph plotting\n",
    "\n",
    "def client_bar_locs(dataframe):\n",
    "    \"\"\"For generating the locations of the bars in the multi-bar plots\"\"\"\n",
    "    \n",
    "    curr_locs = {}\n",
    "    locs_list = []\n",
    "    count_bars = 0\n",
    "    for i in dataframe:\n",
    "        curr_loc = i\n",
    "        if i == 0:\n",
    "            count_bars += 1\n",
    "        try:\n",
    "            latest_loc = curr_locs[i]\n",
    "        except:\n",
    "            curr_locs[i] = i + 1 - bar_width\n",
    "            latest_loc = curr_locs[i]\n",
    "        \n",
    "        new_loc = np.around(latest_loc + bar_width, 1)\n",
    "        curr_locs[i] = new_loc\n",
    "        locs_list.append(new_loc)\n",
    "            \n",
    "    num_bars = len(curr_locs)\n",
    "    locs_list = np.array(locs_list) - (count_bars/2)*bar_width + bar_width/2 #(num_bars*bar_width + bar_width)/2\n",
    "    return locs_list\n",
    "\n",
    "def graph_labels(graph_name, experiment_name, curr_deploy_setup):\n",
    "    \"\"\"Generating the experiment labels based on the permutation\"\"\"\n",
    "    \n",
    "    curr_deploy_setup = ast.literal_eval(curr_deploy_setup)\n",
    "    # generating labels based on experiment name\n",
    "    if graph_name == 'loss':\n",
    "        label_data_packet_loss = curr_deploy_setup['packet_loss']\n",
    "        \n",
    "        if 'e-' in str(label_data_packet_loss):\n",
    "            label_data_packet_loss =  f'{label_data_packet_loss:.5f}'\n",
    "        \n",
    "        label = f'Packet Loss: {label_data_packet_loss}\\%' \n",
    "    elif graph_name == 'latency':\n",
    "        label_data_latency = np.array(curr_deploy_setup['latencies'])\n",
    "        client_primary_latency = label_data_latency[2]\n",
    "        \n",
    "        label = f'Latency: {client_primary_latency} ms'         \n",
    "    elif 'scale' in graph_name:\n",
    "        label_data = curr_deploy_setup['permutation']\n",
    "        replicas = curr_deploy_setup['replicas']\n",
    "        label = str(replicas)\n",
    "    else:\n",
    "        # for if the servers are different\n",
    "        label_data = curr_deploy_setup['permutation']\n",
    "        if label_data.count(label_data[0]) == len(label_data): # check if the same element throughout\n",
    "            first_item = label_data[0]\n",
    "            label = server_dict[first_item]['label']\n",
    "        else:\n",
    "            label = \"[\"\n",
    "            concurrent_server = \"\"\n",
    "            for k in range(len(label_data)):\n",
    "                perm_name = label_data[k]\n",
    "                if 'concurrent' in experiment_name and k == len(label_data)-1:\n",
    "                    # ignore final service on concurrent workload\n",
    "                    concurrent_server = server_dict[perm_name]['label'][-3:-1]\n",
    "                    continue \n",
    "                label_item = server_dict[perm_name]['label'][-3:-1]\n",
    "                if 'C' in label_item:\n",
    "                    label_item = server_dict[perm_name]['label'][-2:-1]\n",
    "                label += f'{label_item},'\n",
    "            label += \"]\"\n",
    "            label = ''.join(label.rsplit(',', 1)) # removing final comma\n",
    "            if 'concurrent' in experiment_name:\n",
    "                label = f'{concurrent_server}: {label}'\n",
    "        if experiment_name == \"2.1.2023-scale\":\n",
    "            replicas = curr_deploy_setup['replicas']\n",
    "            label = label + \" \" + str(replicas)\n",
    "    return label\n",
    "\n",
    "def permutation_analysis(graph_name, df_exp, df_perm):\n",
    "    \"\"\"Selecting the correct colours for the graph bars\"\"\"\n",
    "    \n",
    "    labels = []\n",
    "    for i in range(len(df_exp)):\n",
    "        curr_exp = df_exp.iloc[i]\n",
    "        curr_perm = df_perm.iloc[i]\n",
    "        \n",
    "        # generating legend labels\n",
    "        legend_label = graph_labels(graph_name, curr_exp, curr_perm)\n",
    "        labels.append(legend_label)\n",
    "        \n",
    "    # generating the colours\n",
    "    labels_unique = np.unique(labels)\n",
    "    lu_num = len(labels_unique)\n",
    "    selected_colours = colours[:lu_num]\n",
    "    \n",
    "    colours_dict = {labels_unique[i]: selected_colours[i] for i in range(len(labels_unique))}    \n",
    "    colours_list = [f'#{colours_dict[i]}' for i in labels]\n",
    "    \n",
    "    return labels, colours_list\n",
    "\n",
    "def column_types(df_input):\n",
    "    \"\"\"Selecting columns that only have numerical data\"\"\"\n",
    "    \n",
    "    columns_data_types = df_input.dtypes\n",
    "    unique_data_types = columns_data_types.unique()\n",
    "    \n",
    "    columns = {}\n",
    "    for dtype in unique_data_types:\n",
    "        columns[dtype.name] = (columns_data_types[columns_data_types==dtype].keys()).values\n",
    "    return columns\n",
    "        \n",
    "def results_analyser(df_results, df_storage):\n",
    "    \"\"\"Analysing results and then appending to a dataframe for graphing\"\"\"\n",
    "    \n",
    "    unique_experiments = df_results['experiment'].unique()    \n",
    "    for experiment in unique_experiments:\n",
    "        df_results = df_results.replace([np.inf, -np.inf], np.nan)\n",
    "        experiment_results = df_results[df_results['experiment'] == experiment]\n",
    "        unique_permutations = experiment_results['permutation'].unique()\n",
    "        \n",
    "        columns = column_types(experiment_results) # columns that have numeric data\n",
    "        columns_numeric = columns['float64']\n",
    "        columns_int = columns['int64']\n",
    "        columns_obj = columns['object']\n",
    "        \n",
    "        columns_avg = [x for x in columns_numeric if 'avg' in x]\n",
    "        columns_std = [x for x in columns_numeric if 'std' in x]\n",
    "        for permutation in unique_permutations:\n",
    "            permutation_results = experiment_results[experiment_results['permutation'] == permutation]\n",
    "            client_nums = permutation_results['client'].unique()\n",
    "            for client in client_nums:\n",
    "                curr_client_results = permutation_results[permutation_results['client'] == client].fillna(0)\n",
    "                curr_client_med = curr_client_results[columns_numeric].median().to_frame().T                \n",
    "                curr_client_obj = curr_client_results[columns_obj]\n",
    "                curr_client_int = curr_client_results[columns_int]\n",
    "                cc_obj_int = curr_client_results.groupby(['experiment','permutation', 'client'], as_index=False)[['deployment_latencies', 'deployment_clients']].agg(list)\n",
    "                                \n",
    "                curr_client_res = pd.concat([cc_obj_int, curr_client_med], axis=1)    \n",
    "                \n",
    "                curr_client_results.is_copy = False\n",
    "                curr_client_results['fps_avg'][curr_client_results['fps_avg'] < 0] = 0\n",
    "                \n",
    "                # recalculating the standard deviation\n",
    "                curr_client_res[columns_std] = stats.sem(curr_client_results[columns_avg])\n",
    "\n",
    "                df_storage = pd.concat([df_storage, curr_client_res], axis=0, ignore_index=True)\n",
    "    return df_storage\n",
    "\n",
    "def cpu_normaliser(permutation, service, results):    \n",
    "    \"\"\"Normalising CPU results based on number of CPU cores\"\"\"\n",
    "    \n",
    "    permutation_list = np.array(permutation)\n",
    "    \n",
    "    results_list = np.array(results)\n",
    "    results_normalised = np.array([])\n",
    "\n",
    "    service_loc = service_dict[service]['loc']\n",
    "    \n",
    "    for i in range(len(permutation_list)):\n",
    "        curr_perm = permutation_list[i]\n",
    "        curr_result = results_list[i]\n",
    "        \n",
    "        # if deployed entirely on one server\n",
    "        if '[' not in curr_perm:\n",
    "            server_type = curr_perm[curr_perm.find(\"(\")+1:curr_perm.find(\")\")]\n",
    "            if 'L' in curr_perm:\n",
    "                cores = server_dict['E1']['cores']\n",
    "            elif 'Packet Loss' in curr_perm:\n",
    "                cores = server_dict['E1']['cores']\n",
    "            else:\n",
    "                cores = server_dict[server_type]['cores']\n",
    "        elif '[' in curr_perm:\n",
    "            if ':' in curr_perm:\n",
    "                curr_perm = curr_perm.split(':')[1]\n",
    "            curr_perm_stripped = curr_perm.replace('[', '').replace(']', '').split(',')\n",
    "            curr_server = curr_perm_stripped[service_loc].strip()\n",
    "            cores = server_dict[curr_server]['cores']\n",
    "        norm_result = curr_result / cores\n",
    "        results_normalised = np.append(results_normalised, norm_result)\n",
    "    return results_normalised\n",
    "\n",
    "def gpu_normaliser(permutation, service, results):\n",
    "    \"\"\"Normalising results based on number of CUDA cores\"\"\"\n",
    "    \n",
    "    permutation_list = np.array(permutation)\n",
    "    \n",
    "    results_list = np.array(results)\n",
    "    results_normalised = np.array([])\n",
    "\n",
    "    service_loc = service_dict[service]['loc']\n",
    "    \n",
    "    for i in range(len(permutation_list)):\n",
    "        curr_perm = permutation_list[i]\n",
    "        curr_result = results_list[i]\n",
    "        \n",
    "        # if deployed entirely on one server\n",
    "        if '[' not in curr_perm:\n",
    "            server_type = curr_perm[curr_perm.find(\"(\")+1:curr_perm.find(\")\")]\n",
    "            if 'L' in curr_perm:\n",
    "                cores = server_dict['E1']['cuda_cores']\n",
    "            elif 'Packet Loss' in curr_perm:\n",
    "                cores = server_dict['E1']['cuda_cores']\n",
    "            else:\n",
    "                cores = server_dict[server_type]['cuda_cores']\n",
    "        elif '[' in curr_perm:\n",
    "            if ':' in curr_perm:\n",
    "                curr_perm = curr_perm.split(':')[1]\n",
    "            curr_perm_stripped = curr_perm.replace('[', '').replace(']', '').split(',')\n",
    "            curr_server = curr_perm_stripped[service_loc].strip()\n",
    "            cores = server_dict[curr_server]['cuda_cores']\n",
    "        norm_result = curr_result / cores\n",
    "        results_normalised = np.append(results_normalised, norm_result)\n",
    "    return results_normalised\n",
    "\n",
    "def x_posn_changer(graph_name, x, x_decimals, correct_order):  \n",
    "    \"\"\"Adjusting and correcting the locations of the graph bars\"\"\"\n",
    "    \n",
    "    x = np.around(x, 1)\n",
    "    \n",
    "    x_as_index = int(x)\n",
    "    x_as_decimal = np.around(np.modf(x)[0], 2)\n",
    "\n",
    "    x_decimal_posn = np.where(x_decimals == x_as_decimal)[0][0]\n",
    "    correct_order_posn = correct_order[x_decimal_posn]\n",
    "    \n",
    "    x_decimal = x_decimals[correct_order_posn]\n",
    "    new_x = float(x_as_index + x_decimal)\n",
    "    \n",
    "    # for loss graphs:\n",
    "    if graph_name == 'loss':\n",
    "        if x_decimal == 0.05:\n",
    "            new_x += 1 \n",
    "        elif x_decimal == 0.85:\n",
    "            new_x -= 1\n",
    "    elif graph_name == 'cloud':\n",
    "        if x_decimal == 0.95:\n",
    "            new_x -= 1\n",
    "        elif x_decimal == 0.05:\n",
    "            new_x += 1\n",
    "    elif 'concurrent' in graph_name:\n",
    "        if x_decimal == 0.95:\n",
    "            new_x -= 1\n",
    "        elif x_decimal == 0.25:\n",
    "            new_x += 1\n",
    "    return new_x\n",
    "    \n",
    "def x_posns_rearranger(graph_name, input_x, input_y, correct_order):  \n",
    "    \"\"\"Support function to generate the new x-axis bar locations\"\"\"\n",
    "    \n",
    "    current_order = input_y['permutation'].unique().tolist()\n",
    "    ordered_list = [current_order[i] for i in correct_order]\n",
    "        \n",
    "    x_decimals = np.around(np.modf(input_x)[0], 2).unique()\n",
    "    new_x_posns = input_x.apply(lambda x: x_posn_changer(graph_name, x, x_decimals, correct_order))\n",
    "    return new_x_posns        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72be2694",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T11:09:24.664643Z",
     "start_time": "2023-10-09T11:09:20.511780Z"
    },
    "code_folding": [
     17,
     42,
     56,
     175
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Looping through the top-level graphs in the \"graphs\" variable. This code\n",
    "# needs adjusting based on which scenario you are considering\n",
    "\n",
    "for graph_name in graphs:\n",
    "    bar_width = 0.2\n",
    "    relevant_data_files = graphs[graph_name]['data']\n",
    "    curr_graph_name = graphs[graph_name][\"name\"]\n",
    "    print(f'Current graph is {curr_graph_name} and uses {relevant_data_files}')\n",
    "    data_mask = combined_data['experiment'].apply(lambda x: any(item for item in relevant_data_files if item in x))\n",
    "    relevant_results = combined_data[data_mask]\n",
    "                \n",
    "    # remove rows that are 4 or more clients\n",
    "    relevant_results = relevant_results.drop(relevant_results[relevant_results.client > 3].index)\n",
    "\n",
    "    # calculate median of results across the permutations\n",
    "    df_combined = pd.DataFrame() \n",
    "    df_combined = results_analyser(relevant_results, df_combined)\n",
    "        \n",
    "    # analyse permutations to create legends and assign bar colours \n",
    "    experiments = df_combined['experiment']\n",
    "    permutations = df_combined['permutation']\n",
    "        \n",
    "    perm_analysis = permutation_analysis(curr_graph_name, experiments, permutations)\n",
    "            \n",
    "    legend_labels = perm_analysis[0]\n",
    "    df_combined['legend_labels'] = legend_labels\n",
    "    \n",
    "    bar_colours = perm_analysis[1]\n",
    "    df_combined['bar_colours'] = bar_colours\n",
    "\n",
    "    # find how many clients, i.e., locations of the groups of bars\n",
    "    clients_no = len(df_combined['client'].unique())    \n",
    "    \n",
    "    # prepare x-axis data for plotting, i.e., bar locations\n",
    "    clients = df_combined['client']\n",
    "    bar_locs = client_bar_locs(clients)\n",
    "    df_combined['bar_locs'] = bar_locs\n",
    "    \n",
    "    print(f'There are {len(permutations.unique())} permutations and {clients_no} clients')\n",
    "    \n",
    "    cg_rel_x_posns = df_combined['bar_locs']\n",
    "    cg_rel_permutation = df_combined['permutation']\n",
    "    \n",
    "    # rearrange data in specified permutation order\n",
    "    correct_order = graphs[graph_name]['permutation_order']\n",
    "    cg_x_posns = x_posns_rearranger(curr_graph_name, cg_rel_x_posns, df_combined, correct_order)\n",
    "\n",
    "    plots = graphs[graph_name]['plots']\n",
    "\n",
    "    for plot_key, plot_item in plots.items():\n",
    "        graphs_to_be_made = plot_item['graphs']        \n",
    "        subplots = plot_item['subplots']\n",
    "        figsize = plot_item['figsize']\n",
    "        height_ratios = plot_item['height_ratios']\n",
    "        legends = plot_item['legends']\n",
    "        \n",
    "        try:\n",
    "            legend_size = plot_item['legend_size']\n",
    "        except:\n",
    "            legend_size = 9\n",
    "            \n",
    "        try:\n",
    "            legend_cols = plot_item['legend_cols']\n",
    "        except:\n",
    "            legend_cols = 3\n",
    "        \n",
    "        try:\n",
    "            gridspec_config = plot_item['gridspec']\n",
    "        except:\n",
    "            gridspec_config = {'hspace':0}\n",
    "        \n",
    "        fig, axs = plt.subplots(subplots[0], subplots[1],\n",
    "                                figsize=figsize, sharex=True,\n",
    "                                gridspec_kw=gridspec_config)\n",
    "    \n",
    "        for j in range(len(graphs_to_be_made)):\n",
    "            curr_graph = graphs_to_be_made[f'graph{j}']\n",
    "            subplot_loc = curr_graph['subplot_loc']\n",
    "            \n",
    "            if curr_graph['filler']:\n",
    "                continue\n",
    "            cg_key = curr_graph['results_key'] # curr_graph_key\n",
    "\n",
    "            graph_index = curr_graph['graph_index']\n",
    "            \n",
    "            cg_y_label = curr_graph['name']\n",
    "            axs[subplot_loc].set_ylabel(r'{{{}}}'.format(cg_y_label))\n",
    "            \n",
    "            if cg_key in ['fps', 'success_rate', 'e2e', 'jitter']:\n",
    "                cg_rel_results = df_combined[f'{cg_key}_avg']\n",
    "                cg_rel_err = df_combined[f'{cg_key}_std']\n",
    "                \n",
    "#                 if cg_key == 'fps':\n",
    "#                     print(cg_rel_results)\n",
    "#                     print(cg_rel_err)\n",
    "                \n",
    "                if cg_key == 'jitter':\n",
    "#                     print(cg_rel_results)\n",
    "                    if 'concurrent' not in curr_graph_name:\n",
    "#                         pass\n",
    "                        cg_rel_results /= 1000\n",
    "                        cg_rel_err /= 1000\n",
    "                \n",
    "                cg_rel_labels = df_combined['legend_labels']\n",
    "                cg_rel_colours = df_combined['bar_colours']\n",
    "                \n",
    "                axs[subplot_loc].bar(cg_x_posns, cg_rel_results, yerr=cg_rel_err, \n",
    "                                     label=cg_rel_labels, color=cg_rel_colours,\n",
    "                                     capsize=3, edgecolor='black', zorder=2,\n",
    "                                     linewidth=0.7, width=bar_width, \n",
    "                                     error_kw={'linewidth':0.7, 'capthick':0.7})\n",
    "            elif cg_key in ['cpu', 'memory', 'services']:\n",
    "                if 'queue' in curr_graph_name:\n",
    "                    prev_ser_res = 0\n",
    "                    for service in service_dict:\n",
    "                        if cg_key == 'cpu':\n",
    "                            curr_ser_res = df_combined[f'gpu_{service}_cpu_percent_avg']\n",
    "                            curr_ser_res = cpu_normaliser(df_combined['legend_labels'], service, curr_ser_res)\n",
    "                        elif cg_key == 'memory':\n",
    "                            curr_ser_res = df_combined[f'gpu_{service}_memory.used_avg'] / 1000\n",
    "                            \n",
    "                        axs[subplot_loc].bar(cg_x_posns, curr_ser_res, \n",
    "                                             bottom=prev_ser_res, width=bar_width,\n",
    "                                             color=service_dict[service]['colour'],\n",
    "                                             label=r'$\\texttt{{{}}}$'.format(service),\n",
    "                                             edgecolor='black', zorder=2, linewidth=0.7,\n",
    "                                             hatch='//')\n",
    "                        prev_ser_res += curr_ser_res\n",
    "                else:\n",
    "                    prev_ser_res = 0\n",
    "                    for service in service_dict:\n",
    "                        curr_ser_res = df_combined[f'{cg_key}_{service}_avg']\n",
    "                        if cg_key == 'cpu' and curr_graph_name != \"scale\":\n",
    "                            curr_ser_res = cpu_normaliser(df_combined['legend_labels'], service, curr_ser_res)\n",
    "\n",
    "                        axs[subplot_loc].bar(cg_x_posns, curr_ser_res, \n",
    "                                             bottom=prev_ser_res, width=bar_width,\n",
    "                                             color=service_dict[service]['colour'],\n",
    "                                             label=r'$\\texttt{{{}}}$'.format(service),\n",
    "                                             edgecolor='black', zorder=2, linewidth=0.7,\n",
    "                                             hatch='//')\n",
    "                        prev_ser_res += curr_ser_res\n",
    "            elif 'gpu' in cg_key:\n",
    "                prev_ser_res = 0\n",
    "                for service in service_dict:\n",
    "                    if 'memory' in cg_key:\n",
    "                        curr_ser_res = df_combined[f'gpu_{service}_gpu_memory_usage_avg'] / 1000\n",
    "#                         print(curr_ser_res)\n",
    "                    elif 'util' in cg_key:\n",
    "                        try:\n",
    "                            curr_ser_res = df_combined[f'gpu_{service}_utilization.gpu_avg']\n",
    "                            curr_ser_res = gpu_normaliser(df_combined['legend_labels'], service, curr_ser_res)\n",
    "                        except:\n",
    "                            pass\n",
    "                    axs[subplot_loc].bar(cg_x_posns, curr_ser_res, \n",
    "                                         bottom=prev_ser_res, width=bar_width,\n",
    "                                         color=service_dict[service]['colour'],\n",
    "                                         label=r'$\\texttt{{{}}}$'.format(service),\n",
    "                                         edgecolor='black', zorder=2, linewidth=0.7, \n",
    "                                         hatch='//')\n",
    "                    prev_ser_res += curr_ser_res\n",
    "\n",
    "            axs[subplot_loc].yaxis.grid('major', zorder=0)\n",
    "            axs[subplot_loc].tick_params(axis='both')\n",
    "            \n",
    "            y_axis_lims = curr_graph['y_axis_lims']\n",
    "            axs[subplot_loc].set_ylim(y_axis_lims)\n",
    "            \n",
    "            yat = curr_graph['y_tick_marks']\n",
    "            y_axis_ticks = np.arange(yat[0], yat[1], yat[2])\n",
    "            axs[subplot_loc].set_yticks(y_axis_ticks)\n",
    "        \n",
    "        x_vals = np.arange(0, clients_no, 1) + 1\n",
    "        if 'queue' in curr_graph_name:\n",
    "            for k in range(4):\n",
    "                axs[k].set_xticks(x_vals)    \n",
    "                axs[k].set_xlabel(r'{Number of Clients}')\n",
    "        else:\n",
    "            for k in range(2):\n",
    "                col_loc = 2 \n",
    "                if plot_key == 'plot2':\n",
    "                    col_loc = 2\n",
    "                axs[col_loc,k].set_xticks(x_vals)    \n",
    "                axs[col_loc,k].set_xlabel(r'{Number of Clients}')\n",
    "\n",
    "        services_legend_list = []\n",
    "        for legend_key, legend_item in service_dict.items():\n",
    "            service_name = legend_key\n",
    "            service_colour = legend_item['colour']\n",
    "\n",
    "            services_legend_list.append(mpatches.Patch(facecolor=service_colour, hatch='//',\n",
    "                label=r'$\\texttt{{{}}}$'.format(service_name)))\n",
    "\n",
    "        try:\n",
    "            service_legend = axs[0,1].legend(\n",
    "                handles=services_legend_list, prop={'size': 20}, \n",
    "                bbox_to_anchor=legends['services'], loc='upper left', \n",
    "                    borderaxespad=0, ncol=3, framealpha=1, mode='expand')\n",
    "        except:\n",
    "            service_legend = axs[1].legend(\n",
    "                handles=services_legend_list, prop={'size': 20}, \n",
    "                bbox_to_anchor=legends['services'], loc='upper left', \n",
    "                    borderaxespad=0, ncol=5, framealpha=1, mode='expand')\n",
    "\n",
    "        try:\n",
    "            handles, labels = axs[0,0].get_legend_handles_labels()\n",
    "        except:\n",
    "            handles, labels = axs[0].get_legend_handles_labels()\n",
    "        by_label = dict(zip(labels, handles))\n",
    "\n",
    "        if curr_graph_name == 'loss':\n",
    "            correct_order = [0, 1, 2]\n",
    "        elif curr_graph_name == 'cloud':\n",
    "            correct_order = [1, 2, 0, 3]   \n",
    "        elif 'concurrent_cpu' in curr_graph_name:\n",
    "            correct_order = [1, 0, 3, 2]\n",
    "        elif 'concurrent_gpu' in curr_graph_name:\n",
    "            correct_order = [0, 3, 1, 2]\n",
    "        try:\n",
    "            exp_legend = axs[0,0].legend(\n",
    "                [list(by_label.values())[idx] for idx in correct_order], \n",
    "                [list(by_label.keys())[idx] for idx in correct_order], \n",
    "                prop={'size': legend_size}, bbox_to_anchor=legends['exp'], \n",
    "                loc='upper left', borderaxespad=0, ncol=legend_cols, mode='expand')\n",
    "        except:\n",
    "            exp_legend = axs[0].legend(\n",
    "                [list(by_label.values())[idx] for idx in correct_order], \n",
    "                [list(by_label.keys())[idx] for idx in correct_order], \n",
    "                prop={'size': legend_size}, bbox_to_anchor=legends['exp'], \n",
    "                loc='upper left', borderaxespad=0, ncol=legend_cols, mode='expand')\n",
    "\n",
    "        fig.align_ylabels(axs)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'graphs_conext/{curr_graph_name}_{plot_key}.pdf', bbox_inches='tight', pad_inches=0.01)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdf9092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
